# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
from streamlit_chat import message
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)


#ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
template = """
 ã‚ãªãŸã¯ãŠã˜ã•ã‚“æ§‹æ–‡ã§è¿”ç­”ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚\
                  ãŠã˜ã•ã‚“æ§‹æ–‡ã®ç‰¹å¾´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\
                  *çµµæ–‡å­—ã‚„é¡”æ–‡å­—ã‚’å¤šç”¨ã™ã‚‹\
                  *èªå°¾ã«ã‚«ã‚¿ã‚«ãƒŠã‚’ä½¿ã†\
                  *å¥èª­ç‚¹ã‚’ä»˜ã‘ã‚‹\
                  *é•·æ–‡ã§è¿”ã™\
                  *èã‹ã‚Œã¦ãªã„ã®ã«è‡ªåˆ†ã®è¿‘æ³å ±å‘Šã‚’è¡Œã†\
                  *ãã“ã¯ã‹ã¨ãªãä¸‹å¿ƒãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹æ–‡ç« \
                  *è¦ªã—ããªã„ã®ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãªã‚‹ã¨ã‚¿ãƒ¡å£\
                  ãŠã˜ã•ã‚“æ§‹æ–‡ã®ä¾‹ã‚’ã‚ã’ã¾ã™ã€‚\
                  ãŠç–²ã‚Œã•ã¾ã§ã™ã€‚ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªè¿”ç­”ã‚’ã—ã¾ã™ã€‚\
                  ãŠç–²ã‚Œã‚µãƒğŸ˜ƒâ™¥ã“ã‚“ãªé…ã„æ™‚é–“ğŸ’¤âœ‹ğŸ˜ã«ä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ãªâ‰ï¸ğŸ˜çªç„¶ã ã‘ã©ã€ã€‡ã€‡ã¡ã‚ƒã‚“ã¯ä¸­è¯ğŸœå¥½ãã‚«ãƒŠğŸ˜œâ‰ï¸å°ç”Ÿã¯æ˜æ—¥ã‹ã‚‰åŒ—äº¬ã ã‚ˆğŸ˜ƒğŸ˜ƒâœ‹ãƒ†ãƒ¬ãƒ“ã«å†™ã£ã¡ã‚ƒã£ãŸã‚‰ã©ã†ã—ã‚ˆã€œ(^o^)
"""

# ä¼šè©±ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(template),
    MessagesPlaceholder(variable_name="history"),
    HumanMessagePromptTemplate.from_template("{input}"),
])

#ä¼šè©±ã®èª­ã¿è¾¼ã¿ã‚’è¡Œã†é–¢æ•°ã‚’å®šç¾©
@st.cache_resource
def load_conversation():
    llm = ChatOpenAI(
        streaming=True,
        model_name="gpt-3.5-turbo",
        temperature=0
        
    )
    memory = ConversationBufferMemory(return_messages=True)
    conversation = ConversationChain(
        memory=memory,
        prompt=prompt,
        llm=llm)
    return conversation

# è³ªå•ã¨å›ç­”ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ç©ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
if "generated" not in st.session_state:
    st.session_state.generated = []
if "past" not in st.session_state:
    st.session_state.past = []

# é€ä¿¡ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå¾Œã®å‡¦ç†ã‚’è¡Œã†é–¢æ•°ã‚’å®šç¾©
def on_input_change():
    user_message = st.session_state.user_message
    conversation = load_conversation()
    answer = conversation.predict(input=user_message)

    st.session_state.generated.append(answer)
    st.session_state.past.append(user_message)
    st.session_state.user_message = ""

# ã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³éƒ¨åˆ†ã®UI
st.title("ãŠã˜ã•ã‚“æ§‹æ–‡BOT")
st.caption("ãŠã˜ã•ã‚“æ§‹æ–‡")
st.write("ãŠã˜ã•ã‚“ãŒè³ªå•ã«ç­”ãˆã¾ã™ã€‚")

# ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
chat_placeholder = st.empty()

# ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º
with chat_placeholder.container():
    for i in range(len(st.session_state.generated)):
        message(st.session_state.past[i],is_user=True)
        message(st.session_state.generated[i])

# è³ªå•å…¥åŠ›æ¬„ã¨é€ä¿¡ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
with st.container():
    user_message = st.text_area("è³ªå•ã‚’å…¥åŠ›ã™ã‚‹", key="user_message")
    st.button("é€ä¿¡", on_click=on_input_change)